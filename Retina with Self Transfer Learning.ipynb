{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from random import randint, shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'sample/sample/'\n",
    "annot = pd.read_csv('trainLabels.csv')\n",
    "annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info_list = [(data_path+img_name+'.jpeg', level) for img_name, level in zip(annot['image'], annot['level'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchs = info_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 4752, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread(info_list[0][0])\n",
    "img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size :  224\n",
      "10 train images\n",
      "Total Epochs :  30\n",
      "Number of Batches per Epoch :  0\n"
     ]
    }
   ],
   "source": [
    "train_data = batchs\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 30 \n",
    "\n",
    "num_samples_per_epoch = len(train_data)\n",
    "num_batches_per_epochs = num_samples_per_epoch // batch_size\n",
    "\n",
    "img_size = 224\n",
    "channel_n = 3\n",
    "class_n = 5\n",
    "\n",
    "print(\"Image size : \", img_size)\n",
    "print(\"%d train images\" % (len(train_data)))\n",
    "# print(\"%d  test  images\" % (len(test_data)))\n",
    "print(\"Total Epochs : \", n_epochs)\n",
    "print(\"Number of Batches per Epoch : \", num_batches_per_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model : STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pRelu(x, name='P_ReLU'):\n",
    "    with tf.variable_scope(name):\n",
    "        alpha = tf.get_variable('a', x.get_shape()[-1], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n",
    "        return tf.maximum(0.0, x) + tf.minimum(0.0, alpha*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv2d(input_, output_n, k_h=3, k_w=3, d_h=1, d_w=1, bias=0.0, activation_fc=pRelu, name='conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable('W', [k_h, k_w, input_.get_shape()[-1], output_n], \n",
    "                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable('b', [output_n], initializer=tf.constant_initializer(bias))\n",
    "        conv = tf.nn.conv2d(input_, W, strides=[1, d_h, d_w, 1], padding='SAME', name='conv')\n",
    "        conv_b = tf.nn.bias_add(conv, b)\n",
    "        act = activation_fc(conv_b, 'act')\n",
    "        \n",
    "        tf.summary.histogram('Weight', W)\n",
    "        tf.summary.histogram('Bias', b)\n",
    "        tf.summary.histogram('Conv_Layer', conv)\n",
    "        tf.summary.histogram('Conv_with_bias', conv_b)\n",
    "        tf.summary.histogram('Activation', act)\n",
    "\n",
    "        return act\n",
    "\n",
    "\n",
    "def flatten(input_, name='flatten'):\n",
    "    vec_dim = input_.get_shape()[1:]\n",
    "    n = vec_dim.num_elements()\n",
    "    with tf.name_scope(name):\n",
    "        return tf.reshape(input_, [-1, n])\n",
    "\n",
    "\n",
    "def linear(input_, output_size, stddev=0.02, bias=0.0, name='linear'):\n",
    "    input_size = input_.get_shape().as_list()[1]\n",
    "    with tf.variable_scope(name):\n",
    "        W = tf.get_variable('W', [input_size, output_size], tf.float32,\n",
    "                           initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "        b = tf.get_variable('b', [output_size], initializer=tf.constant_initializer(bias))\n",
    "        logits = tf.nn.xw_plus_b(input_, W, b, name='logits')\n",
    "\n",
    "        tf.summary.histogram('Weight', W)\n",
    "        tf.summary.histogram('Bias', b)\n",
    "        tf.summary.histogram('logit', logits)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "def drop_out(x, prob, name='drop_out'):\n",
    "    with tf.variable_scope(name):\n",
    "        drop_layer = tf.nn.dropout(x, prob)\n",
    "        tf.summary.histogram('Drop_Out', drop_layer)\n",
    "        return drop_layer\n",
    "\n",
    "def stl_cross_enropy(cls_pred, loc_pred, true, a=0.1):\n",
    "    '''\n",
    "    :param a: Hyperparameter. default = 0.1 and increased to 0.9 after 60 epochs\n",
    "             to determine the level of importance between classifier and localizer.\n",
    "    '''\n",
    "    cls_softmax = tf.nn.softmax(cls_pred, name='Clssification_Softmax')\n",
    "    loc_softmax = tf.nn.softmax(loc_pred, name='Localization_Softmax')\n",
    "\n",
    "    return - (1 - a)*tf.reduce_mean(true * tf.log(cls_softmax)) - a * tf.reduce_mean(true * tf.log(loc_softmax))\n",
    "\n",
    "def batch_norm(x, epsilon=1e-5, momentum=0.9, train=True, name=\"batch_norm\"):\n",
    "    with tf.variable_scope(name):\n",
    "        return tf.contrib.layers.batch_norm(x, decay=momentum,\n",
    "                                            updates_collections=None, epsilon=epsilon, scale=True, scope=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class STL(object):\n",
    "    def __init__(self):\n",
    "        self.img_size = img_size\n",
    "        self.class_n = class_n\n",
    "        self.default_act_fn = pRelu\n",
    "        print(\"Self Transfer Learning is Ready\")\n",
    "    \n",
    "    def conv_layer(self, input_):\n",
    "        self.conv1 = conv2d(input_, output_n=96, k_h=11, k_w=11, d_h=4, d_w=4, bias=0.0, activation_fc=self.default_act_fn, name='Conv1')\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name='Pool1')\n",
    "        self.norm1 = batch_norm(self.pool1, epsilon=1e-5, momentum=0.9, train=True, name=\"Batch_Norm1\")\n",
    "        \n",
    "        self.conv2 = conv2d(self.norm1, output_n=256, k_h=5, k_w=5, d_h=1, d_w=1, bias=0.0, activation_fc=self.default_act_fn, name='Conv2')\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name='Pool2')\n",
    "        self.norm2 = batch_norm(self.pool2, epsilon=1e-5, momentum=0.9, train=True, name=\"Batch_Norm2\")\n",
    "        \n",
    "        self.conv3 = conv2d(self.norm2, output_n=384, k_h=3, k_w=3, d_h=1, d_w=1, bias=0.0, activation_fc=self.default_act_fn, name='Conv3')\n",
    "\n",
    "        self.conv4 = conv2d(self.conv3, output_n=384, k_h=3, k_w=3, d_h=1, d_w=1, bias=0.0, activation_fc=self.default_act_fn, name='Conv4')\n",
    "        \n",
    "        self.conv5 = conv2d(self.conv4, output_n=256, k_h=3, k_w=3, d_h=1, d_w=1, bias=0.0, activation_fc=self.default_act_fn, name='Conv5')\n",
    "        self.pool5 = tf.nn.max_pool(self.conv5, ksize=[1,3,3,1], strides=[1,2,2,1], padding='VALID', name='Pool3')\n",
    "        \n",
    "        return self.pool5\n",
    "        \n",
    "        \n",
    "    def classifier(self, input_, keepratio):\n",
    "        self.flat1 = flatten(input_, name='flatten')\n",
    "        self.line1 = linear(self.flat1, 4096, name='fc_layer_4096')\n",
    "        self.drop2 = drop_out(self.line1, prob=keepratio)\n",
    "        self.line2 = linear(self.drop2, 4096, name='fc_layer_1000')\n",
    "        self.drop2 = drop_out(self.line2, prob=keepratio)\n",
    "        self.line3 = linear(self.drop2, self.class_n, name='fc_layer_'+str(self.class_n))\n",
    "        return self.line3\n",
    "    \n",
    "    def localizer(self, input_, alpha):\n",
    "        # Weight : Gaussian dist with standard deviation 0.01, and biases = 0\n",
    "        self.conv6 = conv2d(input_, output_n = 2048, k_h=1, k_w=1, d_h=1, d_w=1, bias=0.0, activation_fc=self.default_act_fn, name='Conv6')\n",
    "        self.gap = tf.reduce_mean( self.conv6, [1,2] )\n",
    "        with tf.variable_scope(\"GAP\"):\n",
    "            self.gap_w = tf.get_variable(\"W\", shape=[2048, self.class_n],initializer=tf.random_normal_initializer(0., 0.01))\n",
    "\n",
    "        return tf.matmul(self.gap, self.gap_w)\n",
    "\n",
    "\n",
    "    def get_classmap(self, conv6, label): \n",
    "        conv6_resized = tf.image.resize_bilinear( conv6, [self.img_size, self.img_size] )\n",
    "        with tf.variable_scope(\"GAP\", reuse=True):\n",
    "            label_w = tf.gather(tf.transpose(tf.get_variable(\"W\")), label)\n",
    "            label_w = tf.reshape( label_w, [-1, 2048, 1] )\n",
    "\n",
    "        conv6_resized = tf.reshape(conv6_resized, [-1, self.img_size*self.img_size, 2048]) \n",
    "\n",
    "        classmap = tf.batch_matmul( conv6_resized, label_w )\n",
    "        classmap = tf.reshape( classmap, [-1, self.img_size, self.img_size] )\n",
    "        \n",
    "        return classmap\n",
    "\n",
    "    \n",
    "    def inference(self, input_, keepratio, alpha):\n",
    "        conv_layers = self.conv_layer(input_)\n",
    "        cls_pred = self.classifier(conv_layers, keepratio)\n",
    "        loc_pred = self.localizer(conv_layers, alpha)\n",
    "        return cls_pred, loc_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test 용 지워야 한다. \n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, channel_n])\n",
    "y = tf.placeholder(tf.int64, shape=[None, 5])\n",
    "alpha = tf.placeholder(tf.float32)\n",
    "keepratio = tf.placeholder(tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_img(img, transform = True):\n",
    "    if transform == True:\n",
    "        \n",
    "        '''\n",
    "        # Cropping Image \n",
    "        row_range = img.shape[0]-img_size\n",
    "        col_range = img.shape[1]-img_size\n",
    "\n",
    "        random_row = randint(0, row_range)\n",
    "        random_col = randint(0, col_range)\n",
    "\n",
    "        img = img[random_row:random_row+img_size, random_col:random_col+img_size]\n",
    "        '''\n",
    "        \n",
    "        # Rotation\n",
    "        rot_deg = randint(0,3) * 90\n",
    "\n",
    "        rot_mat = cv2.getRotationMatrix2D((img.shape[0]//2, img.shape[1]//2), rot_deg, 1)\n",
    "        img = cv2.warpAffine(img, rot_mat, img.shape,flags=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "        # Flipping Image\n",
    "        flip = randint(0,1)\n",
    "        if flip == 1:\n",
    "            img = cv2.flip(img,1)\n",
    "        \n",
    "    img = cv2.resize(img, (img_size, img_size)).reshape(img_size, img_size, channel_n)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def make_batch(batchs, transform = True):\n",
    "    for n, (img_path, level) in enumerate(batchs):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = read_img(img, transform)\n",
    "        label = [0] * 5\n",
    "        label[int(level)] = 1\n",
    "\n",
    "        if n == 0:\n",
    "            img_batch = [img]\n",
    "            label_batch = [label]\n",
    "        else:\n",
    "            img_batch = np.concatenate((img_batch, [img]))\n",
    "            label_batch = np.concatenate((label_batch, [label]))\n",
    "\n",
    "    return img_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, channel_n])\n",
    "y = tf.placeholder(tf.float32, shape=[None, class_n])\n",
    "alpha = tf.placeholder(tf.float32)\n",
    "keepratio = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self Transfer Learning is Ready\n"
     ]
    }
   ],
   "source": [
    "model = STL()\n",
    "cls_pred, loc_pred = model.inference(x, keepratio, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = stl_cross_enropy(cls_pred, loc_pred, y, alpha)   # alpha : 처음엔 0.1로 시작하고서, 60 epochs 후에는 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "learning_rate_decay_factor = 0.1\n",
    "num_epochs_per_decay = 20\n",
    "\n",
    "\n",
    "global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "var_list = tf.trainable_variables()\n",
    "decay_steps = int(num_batches_per_epochs * num_epochs_per_decay)\n",
    "lr = tf.train.exponential_decay(initial_learning_rate,\n",
    "                                global_step,\n",
    "                                decay_steps,\n",
    "                                learning_rate_decay_factor,\n",
    "                                staircase=True)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "grads_and_vars = optimizer.compute_gradients(cost, var_list=var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions ready\n"
     ]
    }
   ],
   "source": [
    "pred = cls_pred + loc_pred\n",
    "corr = tf.equal(tf.argmax(y,1), tf.argmax(pred, 1)) \n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "optm = optimizer.apply_gradients(grads_and_vars, global_step)\n",
    "print (\"Functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_path = 'data/'\n",
    "model_path = 'model/retina/STL_AlexNet'\n",
    "\n",
    "if not os.path.exists(trainset_path):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print(\"Start Training at \", start_time)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        trainLoss = []; trainAcc = []\n",
    "        np.random.shuffle(train_data)\n",
    "        \n",
    "        if epoch < 60:\n",
    "            a = 0.1\n",
    "        else:\n",
    "            a = 0.9\n",
    "        \n",
    "        for batch_idx in range(num_batches_per_epochs):\n",
    "            batch_files = train_data[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "            \n",
    "            train_imgBatch, train_labelBatch = make_batch(train_data, transform = True)\n",
    "            \n",
    "            train_feed = {x: train_imgBatch, y: train_labelBatch, keepratio:0.7, alpha:a}\n",
    "            sess.run(optm, train_feed)\n",
    "            \n",
    "            trainLoss.append(sess.run(cost, train_feed))\n",
    "            trainAcc.append(sess.run(accr, train_feed))\n",
    "\n",
    "        \n",
    "        # Average loss and accuracy\n",
    "        trainLoss = np.mean(trainLoss); trainAcc = np.mean(trainAcc)\n",
    "        \n",
    "        np.random.shuffle(test_data)\n",
    "        test_batch = test_data[:batch_size]\n",
    "        \n",
    "        test_imgBatch, test_labelBatch = make_batch(test_data, transform = False)\n",
    "        \n",
    "        test_feed = {x: test_imgBatch, y: test_labelBatch}\n",
    "        valAcc = sess.run(pred, test_feed)\n",
    "        \n",
    "        if epoch == 0:\n",
    "            print(\"Expected During Time : \", (datetime.now()-start_time)*n_epochs)\n",
    "            print(\"==============================================================================\")\n",
    "        \n",
    "        print (\"[%02d/%02d] trainLoss: %.4f trainAcc: %.2f valAcc: %.2f \\n\" \n",
    "               % (epoch, n_epochs, trainLoss, trainAcc, valAcc))\n",
    "\n",
    "\n",
    "print(\"Training Finished at \", datetime.now())\n",
    "print(\"During Time : \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1,c2,c3,c4,conv5, conv6, gap, output = detector.inference( images_tf )\n",
    "classmap = detector.get_classmap( labels_tf, conv6 )\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.restore( sess, model_path )\n",
    "\n",
    "for start, end in zip(\n",
    "    range( 0, len(testset)+batch_size, batch_size),\n",
    "    range(batch_size, len(testset)+batch_size, batch_size)):\n",
    "\n",
    "    current_data = testset[start:end]\n",
    "    current_image_paths = current_data['image_path'].values\n",
    "    current_images = np.array(map(lambda x: load_image(x), current_image_paths))\n",
    "\n",
    "    good_index = np.array(map(lambda x: x is not None, current_images))\n",
    "\n",
    "    current_data = current_data[good_index]\n",
    "    current_image_paths = current_image_paths[good_index]\n",
    "    current_images = np.stack(current_images[good_index])\n",
    "    current_labels = current_data['label'].values\n",
    "    current_label_names = current_data['label_name'].values\n",
    "\n",
    "    conv6_val, output_val = sess.run(\n",
    "            [conv6, output],\n",
    "            feed_dict={\n",
    "                images_tf: current_images\n",
    "                })\n",
    "\n",
    "    label_predictions = output_val.argmax( axis=1 )\n",
    "    acc = (label_predictions == current_labels).sum()\n",
    "\n",
    "    classmap_vals = sess.run(\n",
    "            classmap,\n",
    "            feed_dict={\n",
    "                labels_tf: label_predictions,\n",
    "                conv6: conv6_val\n",
    "                })\n",
    "\n",
    "    classmap_answer = sess.run(\n",
    "            classmap,\n",
    "            feed_dict={\n",
    "                labels_tf: current_labels,\n",
    "                conv6: conv6_val\n",
    "                })\n",
    "\n",
    "    classmap_vis = map(lambda x: ((x-x.min())/(x.max()-x.min())), classmap_answer)\n",
    "\n",
    "    for vis, ori,ori_path, l_name in zip(classmap_vis, current_images, current_image_paths, current_label_names):\n",
    "        print l_name\n",
    "        plt.imshow( ori )\n",
    "        plt.imshow( vis, cmap=plt.cm.jet, alpha=0.5, interpolation='nearest' )\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
